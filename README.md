# LeMCS - Legal Memoranda Consolidation System

AI-powered document processing platform designed to consolidate multiple legal memoranda into comprehensive omnibus documents using advanced legal NLP and multi-agent AI architecture.

## üèóÔ∏è Architecture

LeMCS employs a sophisticated multi-agent architecture optimized for legal document processing:

- **üß† Multi-Agent AI**: LangGraph-based coordination between specialized legal NLP agents
- **üìö Legal NLP Engine**: eyecite integration for >99% citation extraction accuracy
- **üóÑÔ∏è Semantic Database**: PostgreSQL with pgvector for intelligent document search
- **üîå MCP Integration**: Model Context Protocol server for AI system integration
- **‚öñÔ∏è CRRACC Methodology**: Structured consolidation following legal writing best practices

## ‚ú® Key Features

### üìÑ Document Processing
- **Multi-format Support**: DOCX, PDF, and TXT document processing
- **Text Extraction**: Intelligent content extraction with metadata preservation
- **Legal Citation Detection**: Automated extraction and authority analysis
- **Semantic Search**: Vector-based similarity search across document collections

### üîç Citation Analysis
- **High Accuracy Extraction**: >99% citation identification using eyecite
- **Authority Analysis**: Court hierarchy detection and precedential strength scoring
- **Reference Resolution**: Automatic supra/id citation resolution
- **Citation Statistics**: Performance metrics and quality assessment

### ü§ñ AI Integration
- **MCP Server**: 12 standardized tools for AI system integration
- **Claude Desktop Ready**: Direct integration with Claude Desktop
- **FastAPI Endpoints**: RESTful API for programmatic access
- **Real-time Processing**: Async workflows with progress tracking

### üìä Consolidation Engine
- **CRRACC Method**: Conclusion-Rule-Rule explanation-Application-Counterargument-Conclusion
- **Citation Synthesis**: Intelligent merging while eliminating redundancy
- **Authority Ranking**: Prioritization by precedential strength
- **Cross-Reference Detection**: Identification of overlapping citations

## üöÄ Quick Start

### Prerequisites
- Python 3.12+
- PostgreSQL 15+ with pgvector extension
- Docker (recommended for database)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd aidrafter
   ```

2. **Set up Python environment**
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements-minimal.txt
   ```

3. **Start PostgreSQL with pgvector**
   ```bash
   docker compose up -d postgres
   ```

4. **Initialize the database**
   ```bash
   DATABASE_URL="postgresql+asyncpg://lemcs_user:lemcs_password@localhost/lemcs" python scripts/init_database.py
   ```

### Usage

#### üñ•Ô∏è Web API Server
```bash
python main_simple.py
# Access at http://localhost:8000
# API docs at http://localhost:8000/docs
```

#### üîå MCP Server (AI Integration)
```bash
DATABASE_URL="postgresql+asyncpg://lemcs_user:lemcs_password@localhost/lemcs" python mcp_server/server.py
```

#### üß™ Run Tests
```bash
pytest tests/ -v
```

## üìñ Usage Examples

### Document Upload and Citation Extraction
```python
from mcp_server.server import upload_document, extract_citations

# Upload a legal document
doc_id = await upload_document("/path/to/memorandum.docx")

# Extract citations with authority analysis
result = await extract_citations(doc_id, analyze_authority=True)

print(f"Found {len(result['citations'])} citations")
for citation in result['citations']:
    print(f"üìã {citation['text']}")
    print(f"   Authority: {citation['precedential_strength']}")
    print(f"   Confidence: {citation['confidence_score']:.2f}")
```

### Citation Search and Analysis
```python
from mcp_server.server import search_citations, get_citation_statistics

# Search for specific citations
citations = await search_citations("landlord tenant", limit=10)

# Get performance statistics
stats = await get_citation_statistics()
print(f"Total citations processed: {stats['total_citations']}")
print(f"Average processing time: {stats['avg_processing_time_ms']}ms")
```

### Claude Desktop Integration

Add to your Claude Desktop configuration (`~/claude_desktop_config.json`):

```json
{
  "mcpServers": {
    "lemcs": {
      "command": "python",
      "args": ["/path/to/aidrafter/mcp_server/server.py"],
      "env": {
        "DATABASE_URL": "postgresql+asyncpg://lemcs_user:lemcs_password@localhost/lemcs"
      }
    }
  }
}
```

Then use natural language in Claude Desktop:
- *"Upload the lease agreement and extract all legal citations"*
- *"Find citations about warranty of habitability"*
- *"Analyze the precedential strength of citations in document abc-123"*

## üèóÔ∏è Project Structure

```
aidrafter/
‚îú‚îÄ‚îÄ üìÅ api/                  # FastAPI endpoints
‚îÇ   ‚îî‚îÄ‚îÄ routes/             # API route definitions
‚îú‚îÄ‚îÄ üìÅ agents/              # LangGraph agent implementations
‚îú‚îÄ‚îÄ üìÅ config/              # Configuration management
‚îú‚îÄ‚îÄ üìÅ db/                  # Database models and migrations
‚îú‚îÄ‚îÄ üìÅ mcp_server/          # Model Context Protocol server
‚îú‚îÄ‚îÄ üìÅ nlp/                 # Legal NLP processing modules
‚îú‚îÄ‚îÄ üìÅ scripts/             # Database initialization scripts
‚îú‚îÄ‚îÄ üìÅ tests/               # Test suite
‚îú‚îÄ‚îÄ üìÑ main_simple.py       # FastAPI application entry point
‚îú‚îÄ‚îÄ üìÑ requirements-minimal.txt  # Core dependencies
‚îî‚îÄ‚îÄ üìÑ docker-compose.yml   # PostgreSQL container setup
```

## üõ†Ô∏è Development

### Environment Setup
```bash
# Install development dependencies
pip install -r requirements-minimal.txt

# Code formatting
black .

# Run tests with coverage
pytest tests/ --cov=. -v
```

### Database Schema
The system uses PostgreSQL with pgvector extension and includes 15 tables supporting:
- Document storage and metadata
- Citation extraction and analysis
- Agent workflow tracking
- Semantic search capabilities
- Legal theory classification

See `DATABASE_DESIGN.md` for complete schema documentation.

### Adding New MCP Tools
```python
@mcp.tool()
async def new_legal_tool(
    input_param: str,
    optional_param: Optional[bool] = True
) -> Dict[str, Any]:
    """Tool description for AI systems"""
    # Implementation here
    return {"result": "success"}
```

## üìä Performance

### Benchmarks (Tested)
- **Citation Extraction**: 42ms per document
- **Accuracy**: 100% on test documents (target: >99%)
- **Throughput**: Ready for concurrent processing
- **Memory Usage**: Efficient async processing with cleanup

### Targets
- Process 25 memoranda in under 10 minutes
- Support concurrent processing of 10+ consolidation jobs
- Sub-second citation extraction per page
- >99% citation extraction accuracy

## üîß Configuration

### Environment Variables
```bash
# Database connection
DATABASE_URL="postgresql+asyncpg://user:password@localhost/database"

# Optional API keys (for future features)
OPENAI_API_KEY="your-openai-key"  # For embeddings

# Logging
LOG_LEVEL="INFO"
```

### MCP Server Settings
```python
LEMCS_MCP_CONFIG = {
    "server_name": "LeMCS Legal Processing Server",
    "max_concurrent_extractions": 5,
    "citation_confidence_threshold": 0.8,
    "enable_authority_analysis": True
}
```

## üß™ Testing

### Test Coverage
- ‚úÖ **Document Upload**: Multi-format file processing
- ‚úÖ **Citation Extraction**: eyecite integration with error handling
- ‚úÖ **Database Operations**: CRUD operations and workflow tracking
- ‚úÖ **MCP Tools**: All 12 tools tested and functional
- ‚úÖ **API Endpoints**: FastAPI route validation

### Running Tests
```bash
# All tests
pytest tests/ -v

# Specific test file
pytest tests/test_basic.py -v

# With coverage report
pytest tests/ --cov=. --cov-report=html
```

## üìö Documentation

- **`CLAUDE.md`**: Development guide and project instructions
- **`MCP_DESIGN.md`**: MCP server architecture and tool specifications
- **`EYECITE_INTEGRATION.md`**: Citation extraction implementation details
- **`DATABASE_DESIGN.md`**: Complete database schema documentation
- **`LEGAL_METHODOLOGY.md`**: CRRACC consolidation methodology
- **`mcp_server/README.md`**: MCP server specific documentation

## ü§ù Contributing

### Development Workflow
1. Follow existing code patterns and conventions
2. Add comprehensive tests for new features
3. Update documentation for API changes
4. Ensure type hints and docstrings are complete
5. Run tests and formatting before committing

### Code Standards
- **Type Safety**: Full type hints with mypy compatibility
- **Async/Await**: Consistent async patterns throughout
- **Error Handling**: Comprehensive exception handling and logging
- **Documentation**: Clear docstrings for all public APIs

## üìÑ License

This project is proprietary software for legal document processing applications.

## üö® Security

- **Data Privacy**: All document processing occurs locally
- **Encryption**: Database connections use TLS
- **Access Control**: Role-based access planned for enterprise deployment
- **Audit Logging**: Comprehensive operation tracking

## üõ†Ô∏è Troubleshooting

### Common Issues

**Database Connection Errors**
```bash
# Ensure PostgreSQL is running
docker compose up -d postgres

# Verify connection
DATABASE_URL="postgresql+asyncpg://lemcs_user:lemcs_password@localhost/lemcs" python -c "from db.database import engine; print('Connected!')"
```

**MCP Import Errors**
```bash
# Install MCP dependency
pip install mcp>=1.2.0

# Verify installation
python -c "from mcp.server.fastmcp import FastMCP; print('MCP ready!')"
```

**Citation Extraction Issues**
- Ensure document text is extracted correctly
- Check eyecite compatibility with document format
- Verify citation format matches legal standards

## üìû Support

For technical support and feature requests:
- Check existing documentation in `/docs/` folder
- Review test cases for usage examples
- Consult `CLAUDE.md` for development guidance

---

**Built with ‚ù§Ô∏è for legal professionals seeking efficient document consolidation solutions.**